{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Environment configuration"
      ],
      "metadata": {
        "id": "3pg5sQ7PYvm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To update a package re-install it:\n",
        "! pip uninstall mlxtend -y\n",
        "! pip install -U mlxtend\n",
        "\n",
        "# Now restart: Runtime > Restart Runtime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iql0YmYnYrLS",
        "outputId": "3ab99d52-c5cc-46e7-e100-c0cfa3f35ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: mlxtend 0.21.0\n",
            "Uninstalling mlxtend-0.21.0:\n",
            "  Successfully uninstalled mlxtend-0.21.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mlxtend\n",
            "  Using cached mlxtend-0.21.0-py2.py3-none-any.whl (1.3 MB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from mlxtend) (67.6.1)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.10.1)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.4.4)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.1.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.22.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (8.4.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (5.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.39.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.2->mlxtend) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.2->mlxtend) (3.1.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.0.0->mlxtend) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
            "Installing collected packages: mlxtend\n",
            "Successfully installed mlxtend-0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Used libraries:\n",
        "\n",
        "* [NumPy](https://numpy.org/):\n",
        "    *     NumPy is a Python library for scientific computing, data analysis, and machine learning. It provides a multidimensional array object and functions for working with arrays efficiently.\n",
        "    * NumPy arrays are homogeneous and can store only a single data type, making them more efficient than Python lists.\n",
        "    * NumPy provides many built-in functions for mathematical operations, such as linear algebra and Fourier transforms.\n",
        "    * NumPy is essential for handling and manipulating large arrays and matrices efficiently, which is important in scientific computing, data analysis, and machine learning.\n",
        "    * Unlike Python lists, which are general data structures that can store any type of data, NumPy arrays are homogeneous and can store only a single data type. This makes them much more efficient and faster to operate on, as the operations can be performed in bulk on the entire array, rather than element-by-element as with lists.\n",
        "\n",
        "* [PANel-DAta-S](https://pandas.pydata.org/)\n",
        "    * Pandas is a Python library used for data manipulation and analysis. It provides a DataFrame object that allows you to store and manipulate tabular data.\n",
        "    * Pandas makes it easy to handle missing or incorrect data in your dataset.\n",
        "    * It provides tools for reshaping, merging, and grouping your data.\n",
        "    * Pandas can read and write data from a variety of file formats, such as CSV, Excel, and SQL databases.\n",
        "    * It has built-in functions for data visualization and analysis, such as plotting and statistical analysis.\n",
        "    * Pandas is widely used in data science, finance, and business analysis for its flexibility and ease of use.\n",
        "    * **How is it different from NumPy arrays?** Allows for heterogenous data (columns can have different data types). Adds some more convenient functions on top that are handy for data processing\n",
        "\n",
        "* [MLxtend](http://rasbt.github.io/mlxtend/)  \"Machine learning extensions\" \n",
        "    * contains some convenience functions for machine learning and data science tasks.\n"
      ],
      "metadata": {
        "id": "zFsbNDUNHFpt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1VzAF3L4rm66nI-QX-vBNiW4BbRAI_ZwU\" width=700 alt=\"img\"/>"
      ],
      "metadata": {
        "id": "vIeatGisJaaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to Decission Trees\n",
        "\n",
        "What are decission trees?\n",
        "* Decision trees are a supervised machine learning algorithm used for both\n",
        "classification and regression tasks (see below sections).\n",
        "\n",
        "* A white box type of ML algorithm. It shares internal decision-making logic, which is not available in the black box type of algorithms such as with a neural network. Its training time is faster compared to the neural network algorithm.\n",
        "\n",
        "* A decision tree is a tree-like model where each internal node represents a feature or attribute, each branch represents a decision rule, and each leaf node represents a predicted outcome.\n",
        "\n",
        "* It uses binary tree graph (each node has two children) to assign for each data sample a target value. \n",
        "\n",
        "* The target values are presented in the tree leaves. \n",
        "\n",
        "* To reach to the leaf, the sample is propagated through nodes, starting at the root node. \n",
        "\n",
        "* In each node a decision is made, to which descendant node it should go. \n",
        "\n",
        "* A decision is made based on the selected sample’s feature.\n",
        "\n",
        "* Decision Tree learning is a process of finding the optimal rules in each internal tree node according to the selected metric.\n",
        "\n",
        "* The decision tree is a distribution-free or non-parametric method which does NOT depend upon probability distribution assumptions. \n",
        "\n",
        "* Decision trees can handle high-dimensional data with good accuracy.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1mb78iaZDwoQ5OmVLRYln2EbaBiCxh6Fm\" width=600 alt=\"img\"/>\n",
        "\n",
        "\n",
        "\n",
        "## Types of decision trees with respect to the target values:\n",
        "\n",
        "* **Classification trees** \n",
        "A classification tree is used when the target variable is categorical or discrete in nature. The tree predicts the class of a new instance by following the path from the root node to a leaf node.\n",
        "In scikit-learn it is `DecisionTreeClassifier`.\n",
        "\n",
        "* **Regression trees** A regression tree is used when the target variable is continuous or numeric in nature. The tree predicts the value of a new instance by following the path from the root node to a leaf node and taking the mean value of the training examples at the leaf node.\n",
        "In scikit-learn it is `DecisionTreeRegressor`.\n",
        "\n",
        "Both types of decision trees follow the same basic structure, with each internal node representing a test on an attribute or feature, and each leaf node representing a class or value. The difference is in the way the tree is constructed and the type of output it produces.\n",
        "\n",
        "## How does the Decision Tree algorithm work?\n",
        "\n",
        "The algorithm for building a decision tree typically involves the following steps:\n",
        "\n",
        "1. **Selecting the best attribute to split the data using Attribute Selection Measures (ASM)**:\n",
        "The goal of the decision tree is to split the data into subsets that are as pure as possible with respect to the target variable.\n",
        "The best attribute for splitting the data is the **one that maximizes the information gain** or the **Gini index**.\n",
        "\n",
        "2. **Creating a new internal node for the selected attribute:**\n",
        "Once the best attribute is selected, a new internal node is created for that attribute. Each branch from this node represents a possible value of the attribute.\n",
        "\n",
        "3. **Splitting the data into subsets:**\n",
        "The data is then split into subsets based on the value of the selected attribute. Each subset is used to create a new internal node, which is connected to the parent node by a branch.\n",
        "\n",
        "4. **Recursively applying the algorithm:**\n",
        "The steps 1-3 are recursively applied to each subset until a stopping criterion is met, such as reaching a maximum depth, a minimum number of instances per leaf node, or a _threshold for the purity_ of the subsets.\n",
        "\n",
        "5. **Assigning a class or value to the leaf nodes:**\n",
        "Once the tree is constructed, the class or value to be assigned to each leaf node is determined based on the majority class or mean value of the instances in the subset.\n",
        "\n",
        "6. **Pruning the tree** (optional): \n",
        "Finally, the tree can be pruned to improve its generalization performance and prevent overfitting. This involves removing branches that do not contribute significantly to the accuracy of the tree.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1-rjeTVYph8v63mcHjc44QCs3fOpAwPsE\" width=400 alt=\"img\"/>\n",
        "\n"
      ],
      "metadata": {
        "id": "K5YdJPvx1rRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Glossary:\n",
        "* Basic building block of Decission Tree is one node with `True` and `False` egdes.\n",
        "\n",
        "* Gini<br/>\n",
        "    * $N$ - number of classes\n",
        "    * $P_i$ - probablity of $i^{th}$ class\n",
        "<br/>\n",
        "$$ Gini = \\sum_{i=0}^{N-1} P_i * (1-P_i)$$<br/>\n",
        "\n",
        "* **Entropy** (E) - measure of lack of order \n",
        "$$ E = - \\sum_{i=0}^{i-1} P_i * log_2(P_i), \\mkern9mu E \\in [0,1]$$\n",
        "<br/>\n",
        "$$ P_i = \\frac{\\#\\_of\\_i^{th}\\_class\\_occurence\\_in\\_node}{\\#\\_of\\_total\\_nodes} $$ <br/>\n",
        "Eg. If values in set are split 50/50 then we get the highest entropy $E=1$ \n",
        "\n",
        "> EXAMPLE:\n",
        "> Assuming you are rolling a fair coin and want to know the Entropy of the system. As per the formula given by Shann – Entropy would be equals to $-[0.5 log(0.5) + 0.5 log(0.5)]$. Which is equal to $-0.69$; which is the maximum entropy which can occur in the system. In other words, there will be **maximum randomness** in our dataset if the probable outcomes have same probability of occurrence.\n",
        "\n",
        "* **Information** Gain (IG)\n",
        "$$ IG = E(parent) - [weighted\\_average] * E(children)$$\n",
        "\n",
        ">Example:\n",
        ">\n",
        ">For N=2 so binary classificaotion, $Gini = P_0(1-P_0)+P_1(1-P_1)$ \n",
        ">for $P_1=1-P_0, \\quad Gini = P_0 (1-P_0)+(1-P_0)(1-1+P_0) = 2P_0(1-P_0)$\n",
        "\n",
        "* **Stopping criteria**:\n",
        "    * Max. tree depth\n",
        "    * Min. number of samples a node can have,\n",
        "    * Min. impurity decrease = min. Entropy change that needs to take place for the split to happen\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k-jHmXI7SW8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How a Decission Tree is constructed?\n",
        "There are many algorithms for constructing Decision Trees but the principle of Greediness is common. Algorithms try to search for a variable which give the maximum information gain or divides the data in the most homogenous way. \n",
        "\n",
        "When a decision algorithm tries to split the data, it selects the variable which will give us maximum reduction in system Entropy.\n",
        "\n",
        "EXAMPLE:\n",
        "```\n",
        "Lead Actor \tGenre \tHit(Y/N)\n",
        "Jon Snow \tAction  Yes\n",
        "Jon Snow \tFiction Yes\n",
        "Jon Snow \tRomance No\n",
        "Jon Snow \tAction  Yes\n",
        "Jon Snow \tAction  No\n",
        "Jon Snow \tFiction No\n",
        "Jon Snow \tRomance Yes\n",
        "```\n",
        "For the example of movie success rate – Initial Entropy in the system was:\n",
        "$EntropyParent = -(0.57*log(0.57) + 0.43*log(0.43))$; Which is $0.68$\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=102YWMUIguyWJ--kNS87okWSPsE4QYP0r\" width=600 alt=\"img\"/>\n",
        "\n",
        "Entropy after Method 1 Split\n",
        "\n",
        "$$Entropyleft = -(.75*log(0.75) + 0.25*log(0.25))  = 0.56$$\n",
        "$$Entropyright = -(.33*log(0.33) + 0.67*log(0.67)) = 0.63$$\n",
        "\n",
        "Captured impurity or entropy after splitting data using Method 1 can be calculated using the following formula: \n",
        "\n",
        "$$Entropy (Parent) – Weighted Average of Children Entropy$$\n",
        "\n",
        "Which is,\n",
        "\n",
        "$$0.68 – (4*0.56 + 3*0.63)/7 = 0.09$$\n",
        "\n",
        "This number $0.09$ is generally known as “Information Gain”\n",
        "\n",
        "Entropy after Method 2 Split\n",
        "\n",
        "$$Entropyleft = -(.67*log(0.67) + 0.33*log(0.33))  = 0.63$$\n",
        "$$Entropymiddle = -(.5*log(0.5) + 0.5*log(0.5))  = 0.69$$\n",
        "$$Entropyright = -(.5*log(0.5) + 0.5*log(0.5))  = 0.69$$\n",
        "\n",
        "Now using the method used above, we can calculate the Information Gain as:\n",
        "\n",
        "$$Information Gain = 0.68 – (3*0.63 + 2*0.69 + 2*0.69)/7 = 0.02$$\n",
        "\n",
        "Hence, we can clearly see that **Method 1 gives us more than 4 times information gain compared to Method 2 and hence Method 1 is the best split variable**.\n"
      ],
      "metadata": {
        "id": "JpKkBPKwxMZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example implementation\n",
        "For 3 classes lets implementa Gini and check impurity."
      ],
      "metadata": {
        "id": "Yv7SR0WckSS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gini(samples):\n",
        "    samples_sum = sum(samples)\n",
        "    score = 0\n",
        "    probs = []\n",
        "    for s in samples:\n",
        "        prob = s / samples_sum\n",
        "        probs.append(prob)\n",
        "    for p in probs:\n",
        "        score += p * (1-p)\n",
        "\n",
        "    return score"
      ],
      "metadata": {
        "id": "csnGGyjikaFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [200, 75, 125] # 3 classes numer of elements\n",
        "print(gini(samples))\n",
        "\n",
        "# If we have a sample example with less uncertanity about which class it belongs to:\n",
        "samples1 = [200, 0, 25] # 3 classes numer of elements\n",
        "print(gini(samples1)) # Gini is getting smaller so LESS IMPURE sample in a potential Tree Node\n",
        "\n",
        "samples2 = [200, 0, 0] # 3 classes numer of elements\n",
        "print(gini(samples2)) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osS6zjIpk4Rk",
        "outputId": "237aea6d-f103-4b15-f06e-e79262aa1cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6171875\n",
            "0.04759071980963714\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Entropy:"
      ],
      "metadata": {
        "id": "o5eQIbc0lyiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def entropy(samples):\n",
        "    samples_sum = sum(samples)\n",
        "    score = 0\n",
        "    probs = []\n",
        "    for s in samples:\n",
        "        prob = s / samples_sum\n",
        "        probs.append(prob)\n",
        "    for p in probs:\n",
        "        if p > 0:\n",
        "            score += p * math.log(p)\n",
        "    if score != 0:\n",
        "        score *= -1\n",
        "    return score"
      ],
      "metadata": {
        "id": "2fUBACZrl1D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [200, 75, 125] \n",
        "samples1 = [200, 0, 25] \n",
        "samples2 = [200, 0, 0] \n",
        "print(entropy(samples)) \n",
        "print(entropy(samples1)) \n",
        "print(entropy(samples2)) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYo0nHmXmOya",
        "outputId": "ca451682-a461-4fff-92e5-8cf3b85d00ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0239287996389363\n",
            "0.34883209584303193\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXAMPLE: Dataset Iris\n",
        "\n",
        "petal = płatek \n",
        "sepal = działka\n",
        "\n",
        "Kielich – najbardziej zewnętrzna część kwiatu, składająca się z okółka zielonych **działek kielicha** (łac. sepala, ang. sepals), które rozwinęły się głównie z normalnych liści podkwiatkowych. Zasadniczą funkcją kielicha jest osłanianie wewnętrznych części kwiatu. \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Ts7XW2_QGYfAp289eo7IKm-U_rZ-14Nd\" width=400 alt=\"img\"/>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1D5d9Rjx01Cn90e759glGZapYqxWu66-9\" width=800 alt=\"img\"/>"
      ],
      "metadata": {
        "id": "K7FGlNoXkQxb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Trees (CT)"
      ],
      "metadata": {
        "id": "Fv_3FnIib_RD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore Iris Dataset"
      ],
      "metadata": {
        "id": "IPjYiBxSFTb7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hg8y7Mlk1kzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cac0db0-0a49-4508-857e-3f68c3954748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
            "Iris array shapes:\n",
            "\n",
            "Data shape: (150, 4)\n",
            "Target shape: (150,)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "iris_data = datasets.load_iris()\n",
        "print(iris_data.keys())\n",
        "\n",
        "print(\"Iris array shapes:\\n\")\n",
        "print(f\"Data shape: {iris_data.data.shape}\")\n",
        "print(f\"Target shape: {iris_data.target.shape}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data content: \\n\")\n",
        "print(iris_data.data[:3,:])\n",
        "print(np.unique(iris_data.target))\n",
        "print(iris_data.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqJi2yHX_o2w",
        "outputId": "7855d41b-38fe-4cd1-c1ad-9b7394f54300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data content: \n",
            "\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]]\n",
            "[0 1 2]\n",
            "['setosa' 'versicolor' 'virginica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stratification\n",
        "* Previously, we wrote our own code to shuffle and split a dataset into training, validation, and test subsets, which had one considerable downside.\n",
        "* If we are working with small datasets and split it randomly into subsets, it will affect the class distribution in the samples -- this is problematic since machine learning algorithms/models assume that training, validation, and test samples have been drawn from the same distributions to produce reliable models and estimates of the generalization performance.\n",
        "\n",
        "* The method of ensuring that the class label proportions are the same in each subset after splitting, we use an approach that is usually referred to as \"stratification.\"\n",
        "* Stratification is supported in scikit-learn's `train_test_split` method if we pass the class label array to the `stratify` parameter as shown below."
      ],
      "metadata": {
        "id": "_7nVNCqQWSLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris_data.data[:, [2, 3]]\n",
        "y = iris_data.target\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = \\\n",
        "        train_test_split(X, y, test_size=0.2, \n",
        "                         shuffle=True, random_state=123, stratify=y)\n",
        "\n",
        "np.bincount(y_temp)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = \\\n",
        "        train_test_split(X_temp, y_temp, test_size=0.2,\n",
        "                         shuffle=True, random_state=123, stratify=y_temp)\n",
        "\n",
        "print('Train size', X_train.shape, 'class proportions', np.bincount(y_train))\n",
        "print('Valid size', X_valid.shape, 'class proportions', np.bincount(y_valid))\n",
        "print('Test size', X_test.shape, 'class proportions', np.bincount(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxu2KYkS9LLJ",
        "outputId": "8229a0c5-695c-4d44-e0fa-778ccc827469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size (96, 2) class proportions [32 32 32]\n",
            "Valid size (24, 2) class proportions [8 8 8]\n",
            "Test size (30, 2) class proportions [10 10 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Labels counts in y:', np.bincount(y))\n",
        "print('Labels counts in y_train:', np.bincount(y_train))\n",
        "print('Labels counts in y_test:', np.bincount(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJgbKmQRLZYK",
        "outputId": "bf03e222-fb63-40ac-fed0-31f0546345ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels counts in y: [50 50 50]\n",
            "Labels counts in y_train: [32 32 32]\n",
            "Labels counts in y_test: [10 10 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us use the `scikit learn` library for ready implementations. See documentation for [decision trees](https://scikit-learn.org/stable/modules/tree.html)."
      ],
      "metadata": {
        "id": "s-2pkzsWxxri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "\n",
        "tree_clf = DecisionTreeClassifier(criterion='entropy', \n",
        "                              max_depth=2, \n",
        "                              random_state=1)\n",
        "tree_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "l1xNr7T8LfFI",
        "outputId": "173fc980-9892-4122-cde2-645e1ed48bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', max_depth=2, random_state=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=2, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=2, random_state=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scikit-learn provides some functionalities or parameters that are to be used with a Decision Tree classifier to enhance the model’s accuracy in accordance with the given data.\n",
        "\n",
        "* criterion: This parameter is used to measure the quality of the split. The default value for this parameter is set to “Gini”. If you want the measure to be calculated by entropy gain, you can change this parameter to “entropy”.\n",
        "* splitter: This parameter is used to choose the split at each node. If you want the sub-trees to have the best split, you can set this parameter to “best”. We can also have a random split for which the value “random” is set.\n",
        "* max-depth: This is an integer parameter through which we can limit the depth of the tree. The default value for this parameter is set to None.\n",
        "* min_samples_split: This parameter is used to define the minimum number of samples required to split an internal node.\n",
        "* max_leaf_nodes: The default value of max_leaf_nodes is set to None. This parameter is used to grow a tree with max_leaf_nodes in best-first fashion."
      ],
      "metadata": {
        "id": "4jTUyJFRwzK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_decision_regions(X_train, y_train, tree_clf)\n",
        "\n",
        "plt.xlabel('petal length [cm]')\n",
        "plt.ylabel('petal width [cm]')\n",
        "plt.legend(loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "c1RR2ptaXjzt",
        "outputId": "f26c346a-f65b-42a4-e599-16e8462831bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)\n",
        "Create DataFrame from raw data:"
      ],
      "metadata": {
        "id": "0cDf8l3HFX2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# np.c_ is the numpy concatenate function\n",
        "iris_df = pd.DataFrame(data= np.c_[iris_data['data'], iris_data['target']],\n",
        "                      columns= iris_data['feature_names'] + ['target'])\n",
        "\n",
        "print(iris_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI_8GF-OAOMT",
        "outputId": "fcf6c969-bfa8-45b8-ce2e-4cbd791d097b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   target  \n",
            "0     0.0  \n",
            "1     0.0  \n",
            "2     0.0  \n",
            "3     0.0  \n",
            "4     0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The columns shows the length, width but does not show the group to which this length or width belongs. The group to which these values belong is stored in target_names which can stored in seperate column in our dataframe as.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZB3CkAssGTdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "group_names = pd.Series([iris_data.target_names[ind] for ind in iris_data.target], dtype = 'category')\n",
        "\n",
        "iris_df['group'] = group_names\n",
        "\n",
        "\n",
        "iris_df.head()\n"
      ],
      "metadata": {
        "id": "lqKyMXRwGYtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing:"
      ],
      "metadata": {
        "id": "WuZVtl8SGvRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.boxplot(x=\"group\",y=\"petal length (cm)\",data=iris_df)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_t09wJZaG3Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the relationships between variables; color code by species type\n",
        "di= {0.0: 'Setosa', 1.0: 'Versicolor', 2.0:'Virginica'} # dictionary\n",
        "\n",
        "before= sns.pairplot(iris_df.replace({'target': di}), hue= 'target')\n",
        "before.fig.suptitle('Pair Plot of the dataset without normalization', y=1.08)"
      ],
      "metadata": {
        "id": "PddpTr9KHeRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "\n",
        "text_representation = tree.export_text(tree_clf)\n",
        "print(text_representation)\n"
      ],
      "metadata": {
        "id": "2rkCRmK6aslX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import plot_tree\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "plot_tree(tree_clf, \n",
        "          filled=True, \n",
        "          rounded=True,\n",
        "          class_names=['Setosa', 'Versicolor', 'Virginica'],\n",
        "          feature_names=['petal length', 'petal width']) \n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h7mMS_d7MDZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install graphviz dtreeviz"
      ],
      "metadata": {
        "id": "Iq3jWsHjbYxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dtreeviz  # remember to load the package\n",
        "\n",
        "viz_model = dtreeviz.model(tree_clf, X, y,\n",
        "                target_name=\"target\",\n",
        "                feature_names=iris_data.feature_names,\n",
        "                class_names=list(iris_data.target_names))\n",
        "\n",
        "viz_model.view()     # render as SVG into internal object "
      ],
      "metadata": {
        "id": "4fskPIp2bPG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip uninstall -y matplotlib\n",
        "! pip install matplotlib"
      ],
      "metadata": {
        "id": "0mJ19qOEd-X4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.font_manager as fm\n",
        "from matplotlib import font_manager as fm, pyplot as plt\n",
        "\n",
        "!wget https://github.com/matomo-org/travis-scripts/blob/master/fonts/Arial.ttf \n",
        "\n",
        "font_files = fm.findSystemFonts()\n",
        "\n",
        "# Go through and add each to Matplotlib's font cache.\n",
        "for font_file in font_files:\n",
        "    fm.fontManager.addfont(font_file)\n",
        "\n",
        "\n",
        "t = np.arange(0.0, 2.0, 0.01)\n",
        "s = 1 + np.sin(2*np.pi*t)\n",
        "\n",
        "plt.plot(t, s)\n",
        "\n",
        "plt.xlabel('time (s)')\n",
        "plt.ylabel('voltage (mV)')\n",
        "plt.title('About as simple as it gets, folks')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8OtRrQuRd6De"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exemplary decission tree based on Iris dataset:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1OjOwlUJan12OARb0j0Qr2RoAM_zuJ6ka\" width=400 alt=\"img\"/>"
      ],
      "metadata": {
        "id": "o4JyeEXnJgUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---- \n",
        "# Assigment:\n",
        "Implement `DecisionTree` class that can be used in below script for training:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1e_TdQOIMqyvywpOqmgWDwDkMp4EJ7niZ\" width=500 alt=\"img\"/>\n",
        "\n",
        "Use ONLY Python + NumPy library to fill the following template of the class:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Fesja1OaqwIkl6wRbO255qNhDyr5xize\" width=600 alt=\"img\"/>\n",
        "\n"
      ],
      "metadata": {
        "id": "nhQv1aEp8jni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My implementation DecisionTree"
      ],
      "metadata": {
        "id": "ewSDRBHBYBV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Completed DecisionTree\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value\n",
        "    \n",
        "    def is_leaf_node(self):\n",
        "        return self.value is not None\n",
        "\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, min_samples_split=2, max_depth=100, n_features=None):\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.n_features = n_features\n",
        "        self.root = None\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        self.n_features = X.shape[1] if not self.n_features else min(self.n_features, X.shape[1])\n",
        "        self.root = self._grow_tree(X, y)\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        n_samples, n_features = X.shape\n",
        "        n_labels = len(np.unique(y))\n",
        "    \n",
        "        # Pierwszy warunek stopu: drzewo osiągnęło maksymalną głębokość lub nie można podzielić węzła\n",
        "        if depth >= self.max_depth or n_labels == 1 or n_samples < self.min_samples_split:\n",
        "            leaf_value = self._most_common_label(y)\n",
        "            return Node(value=leaf_value)\n",
        "\n",
        "        feat_idxs = np.random.choice(n_features, self.n_features, replace=False)\n",
        "        best_feat, best_thresh, (left_idxs, right_idxs) = self._best_split(X, y, feat_idxs)\n",
        "\n",
        "        # Drugi warunek stopu: nie można znaleźć najlepszego podziału\n",
        "        if left_idxs.sum() == 0 or right_idxs.sum() == 0:\n",
        "            leaf_value = self._most_common_label(y)\n",
        "            return Node(value=leaf_value)\n",
        "\n",
        "        left = self._grow_tree(X[left_idxs], y[left_idxs], depth + 1)\n",
        "        right = self._grow_tree(X[right_idxs], y[right_idxs], depth + 1)\n",
        "        \n",
        "        return Node(best_feat, best_thresh, left, right)\n",
        "\n",
        "    def _best_split(self, X, y, feat_idxs):\n",
        "        best_gain = -np.inf\n",
        "        split_idx, split_thresh = None, None\n",
        "        for i in feat_idxs:\n",
        "            vals = X[:, i]\n",
        "            for threshold in np.unique(vals):\n",
        "                gain = self._information_gain(y, vals, threshold)\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    split_idx = i\n",
        "                    split_thresh = threshold\n",
        "        left_idxs = X[:, split_idx] <= split_thresh\n",
        "        right_idxs = X[:, split_idx] > split_thresh\n",
        "        \n",
        "        return split_idx, split_thresh, (left_idxs, right_idxs)\n",
        "\n",
        "    def _information_gain(self, y, X_column, threshold):\n",
        "        # Obliczanie entropii rodzica\n",
        "        parent_entropy = self._entropy(y)\n",
        "\n",
        "        # Podział danych na podstawie wartości progowej\n",
        "        left_idxs = X_column <= threshold\n",
        "        right_idxs = X_column > threshold\n",
        "        left_y, right_y = y[left_idxs], y[right_idxs]\n",
        "\n",
        "        # Obliczanie entropii dzieci\n",
        "        left_entropy = self._entropy(left_y)\n",
        "        right_entropy = self._entropy(right_y)\n",
        "\n",
        "        # Obliczanie wartości zysku z informacji\n",
        "        n = len(y)\n",
        "        n_l, n_r = len(left_y), len(right_y)\n",
        "        child_entropy = (n_l/n) * left_entropy + (n_r/n) * right_entropy\n",
        "        information_gain = parent_entropy - child_entropy\n",
        "\n",
        "        return information_gain\n",
        "\n",
        "    def _split(self, X_column, split_thresh):\n",
        "        left_indices = np.where(X_column <= split_thresh)[0]\n",
        "        right_indices = np.where(X_column > split_thresh)[0]\n",
        "        \n",
        "        return left_indices, right_indices\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        hist = np.bincount(y)\n",
        "        ps = hist / len(y)\n",
        "        return -np.sum([p * np.log(p) for p in ps if p>0])\n",
        "\n",
        "    def _traverse_tree(self, x, node):\n",
        "        node = self.root\n",
        "        while not node.is_leaf_node():\n",
        "            if x[node.feature] <= node.threshold:\n",
        "                node = node.left\n",
        "            else:\n",
        "                node = node.right\n",
        "        return node.value\n",
        "\n",
        "    def _most_common_label(self, y):\n",
        "        labels, counts = np.unique(y, return_counts=True)\n",
        "        return labels[np.argmax(counts)]\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._traverse_tree(x, self.root) for x in X])"
      ],
      "metadata": {
        "id": "DXnBCtTB8oGv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Training\n",
        "\"\"\"\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from decision_tree import DecisionTree\n",
        "import numpy as np\n",
        "\n",
        "data = datasets.load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=1234\n",
        ")\n",
        "\n",
        "clf = DecisionTree(max_depth=10)\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "\n",
        "def accuracy(Y_test, y_pred):\n",
        "    return np.sum(y_test == y_pred) / len(y_test)\n",
        "\n",
        "acc = accuracy(y_test, predictions)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "EUkLLae7YIqo",
        "outputId": "cb2a8538-ca89-40c7-e8de-a2bb504087a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    }
  ]
}